{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Model for Translation (ENG to PT)\n",
    "\n",
    "### Using LSTM Autoencoders\n",
    "### Dictionary in WordLevel\n",
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qK2TWV1nm48Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGmBbVVTrm74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vai.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vá.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Oi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng      pt\n",
       "0   Go.    Vai.\n",
       "1   Go.     Vá.\n",
       "2   Hi.     Oi.\n",
       "3  Run!  Corre!\n",
       "4  Run!  Corra!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_table( 'eng2por.txt' , names=[ 'eng' , 'pt' ] )\n",
    "lines = lines.iloc[ : 20000] \n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2_ux1rZnDyY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English max length is 6\n",
      "Encoder input data shape -> (20000, 6)\n",
      "Number of English tokens = 3315\n"
     ]
    }
   ],
   "source": [
    "eng_lines = list()\n",
    "for line in lines.eng:\n",
    "    eng_lines.append(line) \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(eng_lines) \n",
    "tokenized_eng_lines = tokenizer.texts_to_sequences(eng_lines) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_eng_lines:\n",
    "    length_list.append(len(token_seq))\n",
    "max_input_length = np.array(length_list).max()\n",
    "print( 'English max length is {}'.format(max_input_length))\n",
    "\n",
    "padded_eng_lines = preprocessing.sequence.pad_sequences(tokenized_eng_lines , maxlen=max_input_length , padding='post')\n",
    "encoder_input_data = np.array( padded_eng_lines )\n",
    "print( 'Encoder input data shape -> {}'.format(encoder_input_data.shape))\n",
    "\n",
    "eng_word_dict = tokenizer.word_index\n",
    "num_eng_tokens = len( eng_word_dict )+1\n",
    "print( 'Number of English tokens = {}'.format(num_eng_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deB0oX_0pj8R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese max length is 10\n",
      "Decoder input data shape -> (20000, 10)\n",
      "Number of Portuguese tokens = 5488\n"
     ]
    }
   ],
   "source": [
    "port_lines = list()\n",
    "for line in lines.pt:\n",
    "    port_lines.append( '<START> ' + line + ' <END>' )  \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(port_lines) \n",
    "tokenized_port_lines = tokenizer.texts_to_sequences(port_lines) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_port_lines:\n",
    "    length_list.append(len(token_seq))\n",
    "max_output_length = np.array(length_list).max()\n",
    "print('Portuguese max length is {}'.format(max_output_length ))\n",
    "\n",
    "padded_port_lines = preprocessing.sequence.pad_sequences(tokenized_port_lines , maxlen=max_output_length, padding='post' )\n",
    "decoder_input_data = np.array(padded_port_lines )\n",
    "print('Decoder input data shape -> {}'.format(decoder_input_data.shape ))\n",
    "\n",
    "port_word_dict = tokenizer.word_index\n",
    "num_port_tokens = len(port_word_dict )+1\n",
    "print('Number of Portuguese tokens = {}'.format(num_port_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPCTmeL7qj3T",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (20000, 10, 5488)\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data = list()\n",
    "for token_seq in tokenized_port_lines:\n",
    "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
    "    \n",
    "padded_port_lines = preprocessing.sequence.pad_sequences(decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_port_lines = utils.to_categorical(padded_port_lines , num_port_tokens )\n",
    "decoder_target_data = np.array(onehot_port_lines)\n",
    "print( 'Decoder target data shape -> {}'.format(decoder_target_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "Hqb4Bps1s_Lr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    848640      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 256)    1404928     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  525312      embedding_3[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5488)   1410416     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,714,608\n",
      "Trainable params: 4,714,608\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_eng_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.2 , dropout=0.2 )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_port_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( num_port_tokens , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "fnd2H27qt4Hy"
   },
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=32, epochs=25 ) \n",
    "#model.save( 'model.h5' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNhVkiZLvdTq"
   },
   "outputs": [],
   "source": [
    "### Inference part\n",
    "encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(256,))    \n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(256,))\n",
    "    \n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding , initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_hrJcNP-mXb"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( eng_word_dict[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "2Mfco9WKukhS"
   },
   "outputs": [],
   "source": [
    "enc_model, dec_model = encoder_model, decoder_model\n",
    "#enc_model , dec_model = make_inference_models()\n",
    "#enc_model.save( 'enc_model.h5' ) \n",
    "#dec_model.save( 'dec_model.h5' ) \n",
    "#model.save( 'model.h5' ) \n",
    "\n",
    "for epoch in range( encoder_input_data.shape[0] ):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter eng sentence : ' ) ) )\n",
    "    #states_values = enc_model.predict( encoder_input_data[ epoch ] )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = port_word_dict['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    \n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        \n",
    "        for word , index in port_word_dict.items() :\n",
    "            if sampled_word_index == index :                \n",
    "                sampled_word = word \n",
    "                \n",
    "                if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
    "                    stop_condition = True\n",
    "                    \n",
    "                else: \n",
    "                    decoded_translation += word\n",
    "                    \n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Machine_Translation_( Eng-French ).ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "11os3isH4I4X76dwOAQJ5cSRnfhmUziHm",
     "timestamp": 1552703269935
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
